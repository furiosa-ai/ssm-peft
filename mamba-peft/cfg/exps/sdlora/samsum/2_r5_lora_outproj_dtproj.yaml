batch_size: 4
data: samsum
eval_gen:
  max_length: 1024
  min_length: 5
  num_beams: 5
learning_rate: 0.0004
model: state-spaces/mamba-1.4b
no_save: false
num_epochs: 10
peft: cfg/peft/lora/r5/lora_outproj_dtproj.json
prec: bf16
seed: 42
