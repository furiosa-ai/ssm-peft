batch_size: 4
data: samsum
eval_gen:
  max_length: 1024
  min_length: 5
  num_beams: 5
learning_rate: 0.001
model: state-spaces/mamba-1.4b
no_save: false
num_epochs: 10
peft: cfg/peft/lora/r8/lora_inoutproj.json
prec: bf16
